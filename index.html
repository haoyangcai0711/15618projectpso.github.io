<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Parallelizing Particle Swarm Optimization Using CUDA</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
            color: #333;
            background-color: #f4f4f4;
        }
        .container {
            max-width: 1100px;
            margin: auto;
            overflow: hidden;
            padding: 0 20px;
        }
        header {
            background: #35424a;
            color: #ffffff;
            padding-top: 30px;
            min-height: 70px;
            border-bottom: #e8491d 3px solid;
        }
        header h1 {
            margin: 0;
            text-align: center;
        }
        section {
            padding: 20px 0;
            border-bottom: 1px solid #eaeaea;
        }
        h2 {
            color: #35424a;
        }
        p, li {
            margin: 10px 0;
        }
        ul {
            margin: 0;
            padding: 0;
        }
        footer {
            background: #35424a;
            color: #ffffff;
            text-align: center;
            padding: 10px;
            position: relative;
            bottom: 0;
            width: 100%;
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Parallelizing Particle Swarm Optimization Using CUDA</h1>
            <p>Project by Haoyang Cai & Lucy Li</p>
        </div>
    </header>

    <section id="summary">
        <div class="container">
            <h2>Summary</h2>
            <p> We are going to implement a parallel solution of particle swarm optimization using CUDA. </p>
        </div>
    </section>

    <section id="background">
        <div class="container">
            <h2>Background</h2>
            <p>
                Particle Swarm Optimization (PSO) is a robust stochastic optimization technique based on the movement and intelligence of swarms. PSO applies the concept of social interaction to solve complex computational problems efficiently. The algorithm iteratively tries to improve a candidate solution with regard to a given measure of quality. It adapts the stochastic and deterministic aspects by having particles in the swarm follow optimal paths while being randomly influenced by the best solutions found so far.
            </p>
            <p>
                In this project, we plan to implement a parallel version of the Particle Swarm Optimization algorithm using CUDA to leverage the computational power of GPUs. The parallelism inherent in the PSO algorithm stems from the fact that each particle's position update can be computed independently given the global and personal best positions. However, the computation of these best positions themselves requires some form of synchronization or reduction across all particles.
            </p>
            <p>
                A key aspect of PSO that could benefit from parallelism is the evaluation of the fitness function for each particle, which is typically the most compute-intensive part of the algorithm, especially for complex problem spaces. By distributing this computation across multiple GPU cores, we can significantly reduce the execution time of the PSO algorithm.
            </p>
            <p>
                The basic idea can be illustrated with the following pseudocode, outlining the parallel computation within a single iteration of PSO:
            </p>
            <pre>
                for each particle i in parallel:
                  update velocity v[i] based on personal best p[i] and global best g
                  update position x[i] based on velocity v[i]
                  evaluate fitness f[i] of new position x[i]
                reduce all f[i] to find new global best g
            </pre>
        </div>
    </section>
    

    <section id="challenge">
        <div class="container">
            <h2>The Challenge</h2>
            <p>
                Parallelizing the PSO algorithm poses several challenges, primarily related to data dependencies and memory access patterns:
            </p>
            <ul>
                <li>
                    <strong>Data Dependencies and Synchronization:</strong> Ensuring that all particles are updated after the global best is identified requires synchronization, which could introduce overhead and affect scalability.
                </li>
                <li>
                    <strong>Memory Access:</strong> The PSO algorithm can exhibit irregular memory access patterns, particularly when updating a particle's velocity and position based on the global best, which may not exhibit spatial or temporal locality. This can lead to inefficient use of the GPU's memory hierarchy.
                </li>
                <li>
                    <strong>Divergent Execution:</strong> Particles may converge at different rates, leading to divergent execution paths within a warp, which can reduce SIMD efficiency on the GPU.
                </li>
                <li>
                    <strong>Workload Characterization:</strong> Understanding the balance between computation and memory access in PSO is crucial for effective parallelization. If the computation-to-communication ratio is too low, the overhead of memory accesses may dominate execution time.
                </li>
            </ul>
        </div>
    </section>
    

    <section id="resources">
        <div class="container">
            <h2>Resources</h2>
            <p>We will utilize NVIDIA GPUs for implementing the CUDA-based PSO, given their widespread availability and robust development tools. The project will start with a basic sequential PSO implementation, which we will then parallelize. We plan to use the following resources:</p>
            <ul>
                <li><strong>Development Environment:</strong> NVIDIA CUDA Toolkit for developing and profiling the GPU-based implementation.</li>
                <li><strong>Base Code:</strong> We will start with an open-source sequential PSO implementation and then modify it for parallel execution.</li>
                <li><strong>Reference Materials:</strong> We will refer to Kennedy and Eberhart's original paper on PSO, as well as more recent papers discussing parallel implementations of PSO.</li>
                <li><strong>Hardware:</strong> Access to a CUDA-capable GPU is essential. We will use university GPU resources.</li>
            </ul>
            <p>We anticipate needing to explore additional resources on optimizing memory access patterns and reducing synchronization overhead in CUDA. Furthermore, access to advanced profiling tools would be beneficial to understand the performance characteristics of our implementation and identify bottlenecks.</p>
            <p>By undertaking this project, we aim to gain deeper insights into the challenges and strategies for parallel algorithm design, especially in the context of stochastic optimization methods like PSO. The experience will also enhance our understanding of CUDA programming and GPU architecture.</p>
        </div>
    </section>
    

    <section id="goals">
        <div class="container">
            <h2>Goals and Deliverables</h2>
            <p><strong>Core Goals (Plan to Achieve):</strong></p>
            <ul>
                <li><strong>Functional Parallel PSO Implementation:</strong> Develop and demonstrate a working parallel version of the Particle Swarm Optimization algorithm using CUDA, ensuring that it correctly optimizes benchmark functions.</li>
                <li><strong>Performance Analysis:</strong> Provide detailed performance analysis comparing the parallel CUDA implementation to the baseline sequential version. This includes execution time, speedup, and efficiency for various problem sizes and complexities.</li>
                <li><strong>Optimization and Profiling:</strong> Optimize the CUDA implementation to exploit GPU architecture fully, including optimal usage of memory hierarchies and minimizing synchronization overhead. Profile the application to identify and alleviate bottlenecks.</li>
            </ul>
            <p><strong>Stretch Goals (Hope to Achieve):</strong></p>
            <ul>
                <li><strong>Cross-Platform Comparison:</strong> Compare the CUDA-based PSO performance with implementations on other parallel computing platforms (e.g., OpenCL) to highlight the benefits and potential trade-offs of using CUDA.</li>
            </ul>
            <p><strong>Demo:</strong> At the poster session, we plan to showcase a side-by-side comparison of the sequential and parallel PSO implementations, highlighting the performance improvements and scalability of the CUDA-based approach. We will present speedup graphs, execution time comparisons, and possibly an interactive demo showing the algorithm's convergence in real-time on a chosen problem set.</p>
            <p><strong>Learning Objectives:</strong> Through this project, we aim to learn effective strategies for parallelizing inherently parallel algorithms like PSO on modern GPU architectures, understand how to mitigate common parallelization challenges (e.g., synchronization, memory access patterns), and gain insights into CUDA-specific optimizations that can maximize performance.</p>
            <p><strong>Questions that we plan to answer:</strong></p>
            <ul>
                <li>How does parallelization impact the convergence behavior and solution quality of PSO?</li>
                <li>What are the primary bottlenecks in parallelizing PSO using CUDA, and how can they be overcome?</li>
                <li>How do different optimization strategies affect the performance and scalability of the CUDA-based PSO on various GPU architectures?</li>
            </ul>
        </div>
    </section>
    

    <section id="platform">
        <div class="container">
            <h2>Platform Choice</h2>
            <p>
                In our project, we choose to use a variety of platforms to evaluate the performance and the scalability of our parallel solution to PSO using CUDA. We will be using GHC machines with NVIDIA RTX 2080 GPUs, our PC with a RTX 4090 GPU, and PSC machines with 64 CPU cores. Testing on different GPUs will show us whether our solution scales to newer generations of GPUs. By comparing our GPU code to existing CPU implementations running on the 64-core PSC machines, we can see if using GPUs will provide a substantial advantage for the PSO problem.
            </p>
        </div>
    </section>
    

    <section id="schedule">
        <div class="container">
          <h2>Schedule</h2>
          <ul>
            <li>Week 1: Set up environment, implement sequential PSO, discuss parallelization strategies</li>
            <li>Week 2: Develop parallel CUDA implementation, test and debug, start collecting performance metrics</li>
            <li>Week 3: Optimize CUDA implementation, conduct performance testing on GPUs, start comparative analysis</li>
            <li>Week 4: Run CPU-based PSO, conduct comparative analysis, prepare visualizations and project poster</li>
            <li>Week 5: Finalize poster, prepare demo, explore extended platform analysis, present project findings</li>
          </ul>
        </div>
    </section>

    <footer>
        <p>Project for [Course Name], [Year].</p>
    </footer>
</body>
</html>
